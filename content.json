{"meta":{"title":"PlusL","subtitle":"如果结果不如你所愿，就在尘埃落定前奋力一搏","description":"PlusL个人博客，主要用作学习生活记录分享，欢迎~","author":"PlusL","url":"http://plus-l.github.io","root":"/"},"pages":[],"posts":[{"title":"Princeton Algorithm I 第一周  Union-Find（并查集）学习记录","slug":"Princeton-Algorithm-I-第一周-Union-Find（并查集）学习记录","date":"2022-12-01T01:32:47.000Z","updated":"2022-12-01T03:05:45.266Z","comments":true,"path":"2022/12/01/Princeton-Algorithm-I-第一周-Union-Find（并查集）学习记录/","link":"","permalink":"http://plus-l.github.io/2022/12/01/Princeton-Algorithm-I-%E7%AC%AC%E4%B8%80%E5%91%A8-Union-Find%EF%BC%88%E5%B9%B6%E6%9F%A5%E9%9B%86%EF%BC%89%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/","excerpt":"","text":"0. Overviewhttps://www.coursera.org/learn/algorithms-part1/supplement/aYr6R/overviewWe begin our study of algorithms with a motivating example and an overview of the use of the scientific method for studying algorithm performance.Lecture: Union−Find.Lecture: Analysis of Algorithms.Programming Assignment: Percolation. Steps to developing a usable algorithm. Model the problem. Find an algorithm to solve it. Fast enough? Fits in memory? If not, figure out why. Find a way to address the problem. Iterate until satisfied. 1. dynamic connectivity（动态连接）要求设计一个并查集的数据结构，详细内容向下看给出的几个API要求如下： union – 将两个并查集合并 connected – 检查两个object是否连通（连通遵守连通性，即 a - b ，b - c， 则a - c） 将连接模型化，其实最后就是分出来几个子集 API 如下： 2. quick find 「eager approach」查找：我们最容易想到的方式就是使用贪心算法，直接使用一个id[]数组存各object之间的关系，如果**i**位置的**id[i]**** 与****j**位置的**id[j]**相等，则表示他们在同一个子集里合并：合并相对复杂一些，需要遍历数组找到所有**id**等于**id[i]**的元素，然后把它们修改为**id[j]**，也算是非常朴实无华的操作了show me the code !! 123456789101112131415161718192021222324252627282930public class QuickFindUF &#123; private int[] id; /** * init QuickFindUF by capacity N * @param N */ public QuickFindUF(int N) &#123; id = new int[N]; for (int i = 0; i &lt; N; i++) &#123; id[i] = i; &#125; &#125; public Boolean connected(int p, int q) &#123; return id[p] == id[q]; &#125; public void union(int p, int q) &#123; int pid = id[p]; int qid = id[q]; // 循环遍历id数组，将所有目前处在p子集里的id值修改为qid（也即pq子集合并，全部归为q子集） for (int i = 0; i &lt; id.length; i++) &#123; if (id[i] == pid) id[i] = qid; &#125; &#125;&#125; 好，接下来是喜闻乐见的代码复杂度分析，这里的复杂度主要集中在union操作上，为O(n)，但union操作是一个常用操作，一般人们使用union就会执行n次，执行n次union操作的复杂度来到了O(n**2)**，非常恐怖的数字（程序员最不想见到的数字） 那么接下来应该如何优化呢？走着 3. quick union 「lazy approach」与quick find的策略完全相反，这里采用的是“懒策略”，尽可能的避免计算直到不得不计算 quick union 仍然采用数组作为基底，但这里的数组所表示的含义发生了变化：i位置存放的元素不再指其所在的子集中，而是成为了一颗树，存放的元素表示的是i的父节点，还有一个属性root表示的是i对应的根节点。比如上图中，3.parent = 4,3.root = 9 这样的数据结构，find和union操作会有哪些变化呢？看图Find操作由原本的“找组织”变为了找根节点（root）union操作不再需要遍历整个数组去修改对应下标的元素，而只需要找到p、q二者的root，然后将两个root进行连接，如上图所示，要union 3 and 5，just find the root of 3(9) and the root of 5(6) , then 9.parent = 6 or 6.parent = 9连接起来就可以咯 show me the code !! 1234567891011121314151617181920212223242526272829public class QuickUnionUF &#123; private int[] id; public QuickUnionUF(int N) &#123; id = new int[N]; for (int i = 0; i &lt; N;i ++) &#123; id[i] = i; &#125; &#125; private int root(int index) &#123; // 当前下标不等于其存储元素，意味着他的元素被修改过，也就是他并不是根节点（根节点元素不会被修改） while (index != id[index]) index = id[index]; return index; &#125; public Boolean connected(int p, int q) &#123; return root(p) == root(q); &#125; public void union(int p, int q) &#123; int i = root(p); int j = root(q); id[i] = j; &#125;&#125; 那么quick union的时间复杂度如何呢？union操作的复杂度顺利降到了常量级（O(1)），执行n次则为O(n)Find操作复杂度上升到了O(n) - 最坏情况，quick-union的缺陷在于，他维护的树在最坏情况下会变得非常高，查找起来时间非常昂贵 4. Weighted quick union 加权快合并解决树过高的方式很简单，给子树加上权重，将权重（可以是高度可以是节点数，这里是节点数）小的作为权重大的树的子树 树的高度来到了O(logN)！show me the code !! 123456789101112131415161718192021222324252627282930313233public class WeigthedQuickUnion &#123; private int[] id; private int[] sz; public WeigthedQuickUnion(int N) &#123; id = new int[N]; sz = new int[N]; for (int i = 0; i &lt; N;i ++) &#123; id[i] = i; sz[i] = 1; &#125; &#125; private int root(int index) &#123; // 当前下标不等于其存储元素，意味着他的元素被修改过，也就是他并不是根节点（根节点元素不会被修改） while (index != id[index]) index = id[index]; return index; &#125; public Boolean connected(int p, int q) &#123; return root(p) == root(q); &#125; public void union(int p, int q) &#123; int i = root(p); int j = root(q); if (i == j) return; if (sz[i] &lt; sz[j]) &#123; id[i] = j; sz[j] += sz[i]; &#125; else &#123; id[j] = i; sz[i] += sz[j]; &#125; &#125;&#125; 教授最后提及到一个比加权更好的算法，但不在这门课的讨论范围了，有时间一定去研究研究，还蛮好玩的————————————- I’m Dividing line ——————————————————-更新！ 我来填坑这个算法啦，其实思路并不难，就是将 快速联合（quick union）与路径压缩相结合，在计算完p的根之后，将每个检查节点的id设置为指向该根。（意思就是把所有树的根节点干脆一股脑指向根节点，这样这棵树就会更矮更胖） Two-pass implementation: 我们可以在**root()**方法中加上第二个循环，将每个检查节点的id都设置为根 Simpler one-pass variant: 使路径中的每一个其他节点指向它的祖父节点(从而使路径长度减半)。 （我们没理由不去让整棵树完全平坦！但我没看懂😢）————————————- I’m Dividing line too —————————————————-教授还说，人们寻找了很多年try to find a algorithm to let the Union-Find down to linear 将并查集算法时间复杂度降低到线性，但最后证明 – 并查集算法不存在线性时间算法 5. Union-Find Application 快速并查集的应用教授举例了一个很帅的应用 – 渗滤模型n*n的图，如果有一条通道能使top连接到bottom，则表示可以渗滤，在这个过程中打开的通道完全是随机的。 渗滤模型是否渗滤取决于位置空置概率p。当 n 逐渐增大时，存在一个尖锐的阈值 p* ：p &gt; p* : 几乎所有的渗滤模型都能渗滤p &lt; p* : 几乎都不能好！ question 来啦，这个p*的值是多少呢？ 这里就引出了一个模拟 – Monte Carlo simulation（蒙特卡罗模拟） Initialize N-by-N whole grid to be blocked Declare random sites open until top connected to bottom. （随机开放位置，直到top连接bottom） Vacancy percentage estimates p*. 在这个模拟中，如何检测连通性是个大问题，如果采用遍历的话估计要跑30年（百万次模拟取数据），而咱们可以用上述的并查集将top和bottom作为虚拟site，只需通过quick union构件并查集便可以飞快的检验连通性，最终得出的threadhold结果长这样：优雅！太优雅了 6. 一些小吐槽 正片结束，吐槽环节，好的老师真的是兴趣的开始，遥想当年刚开始接触算法时，大学的老师一口浓重的地方口语 + 龟速的念PPT 把我原本想学习算法加入ACM的兴趣全数磨灭，现在只能感叹当时为何没有发现这一神仙课程和这个宝藏教授呢。不得不说的是，国内的CS教育确实不如国外，这是现状，也是我们需要认清的，同学们多多努力，期待你们成为优秀的CS教授打破国内CS教育差这个说法！","categories":[],"tags":[{"name":"DataStructure and Algorithm,Princeton Algorithm","slug":"DataStructure-and-Algorithm-Princeton-Algorithm","permalink":"http://plus-l.github.io/tags/DataStructure-and-Algorithm-Princeton-Algorithm/"}]},{"title":"面向对象你不知道对象是什么？","slug":"面向对象你不知道对象是什么？","date":"2022-12-01T01:30:15.000Z","updated":"2022-12-01T01:32:28.251Z","comments":true,"path":"2022/12/01/面向对象你不知道对象是什么？/","link":"","permalink":"http://plus-l.github.io/2022/12/01/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%BD%A0%E4%B8%8D%E7%9F%A5%E9%81%93%E5%AF%B9%E8%B1%A1%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/","excerpt":"","text":"不会真有人用了这么久面向对象语言还不知道对象是个啥吧（doge😏 一、对象的组成对象由：对象头、实例数据、填充字节填充字节就不谈了，就是补充空字节满足Java对象必须是8byte的倍数。 来来来，大的要来了😱 ClassPointer：很好理解，他指向了当前对象类型所在方法区中的类型数据（也就是跑到方法区去找这个对象到底是啥类型） 方法区在JDK 1.8后移至元空间（MetaSpace） 2. MarkWordMarkWord存储了很多与当前对象运行时状态相关的数据，图如下：对象头被设计的极小，MarkWord只有32bit，能够很大程度的节省空间。我们可以多关注最后面的锁标志位，锁标志位分别代表着锁的四种状态：无锁、偏向锁、轻量级锁、重量级锁。而这里的锁状态与synchronized关键字有关 （详见Java关键字)需要注意的是：锁只能升级不能降级:::warning锁的升级全在MarkWord中，现在我们来看看锁到底是如何升级的 无锁到偏向锁：最初始时，对象为无锁状态，锁标志位为01，且是否偏向锁位为0.当一个线程前来加锁，对象头记录这个对象的HashCode，并设置偏向锁。 偏向锁到轻量级锁：突然有一天，对象发现不止有一个线程在争抢他（多个线程正在竞争锁），那么偏向锁就升级为轻量级锁。 在轻量级锁中，线程争抢对象的方式是CAS。 轻量级锁到重量级锁：当对象被轻量级锁锁定，其他线程想要获得该对象就需要进行自旋抢，当正在自旋的线程超过一个，则升级为重量级锁。:::","categories":[],"tags":[{"name":"Operating System","slug":"Operating-System","permalink":"http://plus-l.github.io/tags/Operating-System/"}]},{"title":"操作系统（大合集，有点杂）","slug":"操作系统（大合集，有点杂）","date":"2022-12-01T01:30:15.000Z","updated":"2022-12-01T01:31:16.553Z","comments":true,"path":"2022/12/01/操作系统（大合集，有点杂）/","link":"","permalink":"http://plus-l.github.io/2022/12/01/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%88%E5%A4%A7%E5%90%88%E9%9B%86%EF%BC%8C%E6%9C%89%E7%82%B9%E6%9D%82%EF%BC%89/","excerpt":"","text":"操作系统、计算机网络这块还是得看林哥「小林coding」 https://xiaolincoding.com/os/ 零、计算机结构1. 冯诺依曼计算机模型现代计算机模型是基于-冯诺依曼计算机模型计算机在运行时，先从内存中取出第一条指令，通过控制器的译码，按指令的要求，从存储器中取出数据进行指定的运算和逻辑操作等加工，然后再按地址把结果送到内存中去，接下来，再取出第二条指令，在控制器的指挥下完成规定操作，依此进行下去。直至遇到停止指令 2. 计算机五大核心组成部分 控制器：是整个计算机的中枢神经，其功能是对程序规定的控制信息进行解释，根据其要求进行控制，调度程序、数据、地址，协调计算机各部分工作及内存与外设的访问等。 运算器：运算器的功能是对数据进行各种算术运算和逻辑运算，即对数据进行加工处理。 存储器：存储器的功能是存储程序、数据和各种信号、命令等信息，并在需要时提供这些信息。 输入：输入设备是计算机的重要组成部分，输入设备与输出设备合你为外部设备，简称外设，输入设备的作用是将程序、原始数据、文字、字符、控制命令或现场采集的数据等信息输入到计算机。 常见的输入设备有键盘、鼠标器、光电输入机、磁带机、磁盘机、光盘机等。 输出：输出设备与输入设备同样是计算机的重要组成部分，它把外算机的中间结果或最后结果、机内的各种数据符号及文字或各种控制信号等信息输出出来，微机常用的输出设备有显示终端CRT、打印机、激光印字机、绘图仪及磁带、光盘机等。 3. 计算机结构分成以下 5 个部分：输入设备；输出设备；内存；中央处理器；总线。 4. 内存在冯诺依曼模型中，程序和数据被存储在一个被称作内存的线性排列存储区域。存储的数据单位是一个二进制位，英文是 bit，最小的存储单位叫作字节，也就是 8 位，英文是 byte，每一个字节都对应一个内存地址。内存地址由 0 开始编号，比如第 1 个地址是 0，第 2 个地址是 1， 然后自增排列，最后一个地址是内存中的字节数减 1。我们通常说的内存都是随机存取器，也就是读取任何一个地址数据的速度是一样的，写入任何一个地址数据的速度也是一样的。 5. CPU冯诺依曼模型中 CPU 负责控制和计算，为了方便计算较大的数值，CPU 每次可以计算多个字节的数据。 如果 CPU 每次可以计算 4 个 byte，那么我们称作 32 位 CPU； 如果 CPU 每次可以计算 8 个 byte，那么我们称作 64 位 CPU。 这里的 32 和 64，称作 CPU 的位宽。 寄存器CPU 要进行计算，比如最简单的加和两个数字时，因为 CPU 离内存太远，所以需要一种离自己近的存储来存储将要被计算的数字。这种存储就是寄存器，寄存器就在 CPU 里，控制单元和逻辑运算单元非常近，因此速度很快。常见的寄存器种类： 通用寄存器，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。 程序计数器，用来存储 CPU 要执行下一条指令所在的内存地址，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令的地址。 指令寄存器，用来存放程序计数器指向的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里。 十、 内存管理（段页、虚拟内存）1. 逻辑地址与物理地址 我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。 物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址，物理地址是内存单元真正的地址。 编译时只需确定变量x存放的相对地址是100 ( 也就是说相对于进程在内存中的起始地址而言的地址)。CPU想要找到x在内存中的实际存放位置，只需要用进程的起始地址+100即可。 相对地址又称逻辑地址，绝对地址又称物理地址。 2. 内存管理有几种方式1. 块式管理：将内存分为几个固定大小的块，每个块中只包含一个进程，如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了，这些在每个块中未被利用的空间，我们称之为碎片。 2. 页式管理：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片，页式管理通过页表对应逻辑地址和物理地址。 3. 段式管理页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义， 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 ，段式管理通过段表对应逻辑地址和物理地址。 4. 段页式管理段页式管理机制结合了段式管理和页式管理的优点，简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说段页式管理机制中段与段之间以及段的内部的都是离散的。 二、进程调度算法1、 先来先服务 first-come first-serverd（FCFS）非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。2、 短作业优先 shortest job first（SJF）非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。3、最短剩余时间优先 shortest remaining time next（SRTN）最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。4、时间片轮转将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。时间片轮转算法的效率和时间片的大小有很大关系： 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。 5、优先级调度为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。6、多级反馈队列一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。 三、动态分区分配算法（页面置换）1、首次适应算法算法思想：每次都从低地址开始查找，找到第–个能满足大小的空闲分区。如何实现：空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区链( 或空闲分[表)，找到大小能满足要求的第-一个空闲分区。 2、最佳适应算法算法思想:由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区,即，优先使用更小的空闲区。如何实现:空闲分区按容量递增次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。 3、最坏适应算法又称最大适应算法(Largest Fit)算法思想:为了解决最佳适应算法的问题—即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。如何实现:空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。 4、邻近适应算法算法思想：首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。如何实现：空闲分区以地址递增的顺序排列(可排成-一个循环链表)。每次分配内存时从上次查找结束的位置开始查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区。 5、总结首次适应不仅最简单，通常也是最好最快，不过首次适应算法会使得内存低地址部分出现很多小的空闲分区，而每次查找都要经过这些分区，因此也增加了查找的开销。邻近算法试图解决这个问题，但实际上，它常常会导致在内存的末尾分配空间分裂成小的碎片，它通常比首次适应算法结果要差。最佳导致大量碎片，最坏导致没有大的空间。进过实验，首次适应比最佳适应要好，他们都比最坏好。 四、进程同步的方法1. 临界区对临界资源进行访问的那段代码称为临界区。为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。 2. 同步与互斥 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。 互斥：多个进程在同一时刻只有一个进程能进入临界区。 3. 信号量信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。 down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0； up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。 down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。 4. 管程信号量机制的缺点：进程自备同步操作，P(S)和V(S)操作大量分散在各个进程中，不易管理，易发生死锁。1974年和1977年，Hore和Hansen提出了管程。管程特点：管程封装了同步操作，对进程隐蔽了同步细节，简化了同步功能的调用界面。用户编写并发程序如同编写顺序(串行)程序。 五、介绍一下几种典型的锁？读写锁 多个读者可以同时进行读 写者必须互斥（只允许一个写者写，也不能读者写者同时进行） 写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者） 互斥锁一次只能一个线程拥有互斥锁，其他线程只有等待互斥锁是在抢锁失败的情况下主动放弃CPU进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以互斥锁在加锁操作时涉及上下文的切换。互斥锁实际的效率还是可以让人接受的，加锁的时间大概100ns左右，而实际上互斥锁的一种可能的实现是先自旋一段时间，当自旋的时间超过阀值之后再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）的效果可能不亚于使用自旋锁 自旋锁如果进线程无法取得锁，进线程不会立刻放弃CPU时间片，而是一直循环尝试获取锁，直到获取为止。如果别的线程长时期占有锁，那么自旋就是在浪费CPU做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高。 六、你知道哪几种线程锁（POSIX）？ 互斥锁（mutex） 互斥锁属于sleep-waiting类型的锁。例如在一个双核的机器上有两个线程A和B，它们分别运行在core 0和core 1上。假设线程A想要通过pthread_mutex_lock操作去得到一个临界区的锁，而此时这个锁正被线程B所持有，那么线程A就会被阻塞，此时会通过上下文切换将线程A置于等待队列中，此时core 0就可以运行其他的任务（如线程C）。 条件变量(cond) 自旋锁(spin) 自旋锁属于busy-waiting类型的锁，如果线程A是使用pthread_spin_lock操作去请求锁，如果自旋锁已经被线程B所持有，那么线程A就会一直在core 0上进行忙等待并不停的进行锁请求，检查该自旋锁是否已经被线程B释放，直到得到这个锁为止。因为自旋锁不会引起调用者睡眠，所以自旋锁的效率远高于互斥锁。 虽然它的效率比互斥锁高，但是它也有些不足之处： 自旋锁一直占用CPU，在未获得锁的情况下，一直进行自旋，所以占用着CPU，如果不能在很短的时间内获得锁，无疑会使CPU效率降低。 在用自旋锁时有可能造成死锁，当递归调用时有可能造成死锁。 自旋锁只有在内核可抢占式或SMP的情况下才真正需要，在单CPU且不可抢占式的内核下，自旋锁的操作为空操作。自旋锁适用于锁使用者保持锁时间比较短的情况下。 七、常见的几种磁盘调度算法读写一个磁盘块的时间的影响因素有： 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上） 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上） 实际的数据传输时间 其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。 1. 先来先服务 FCFS按照磁盘请求的顺序进行调度。优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。 2. 最短寻道时间优先优先调度与当前磁头所在磁道距离最近的磁道。虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。 3. 扫描算法（SCAN）电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。 八、页面置换算法1. 最佳置换算法（OPT）：这是一种理想情况下的页面置换算法，但实际上是不可能实现的。该算法的基本思想是：发生缺页时，有些页面在内存中，其中有一页将很快被访问（也包含紧接着的下一条指令的那页），而其他页面则可能要到10、100或者1000条指令后才会被访问，每个页面都可，以用在该页面首次被访问前所要执行的指令数进行标记。最佳页面置换算法只是简单地规定：标记最大的页应该被置换。 2. 先进先出（FIFO）：先进先出置换算法(FIFO) :每次选择淘汰的页面是最早进入内存的页面 实现方法:把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面队列的最大长度取决于系统为进程分配了多少个内存块。 3. 最近最久未使用（LRU）：每次淘汰的页面是最近最久未使用的页面 实现方法:赋予每个页面对应的页表项中，用访问字段记录该页面自.上次被访问以来所经历的时间t(该算法的实现需要专门的硬件支持，虽然算法性能好，但是实现困难，开销大) 「基于 HashMap 和 双向链表实现 LRU 」整体的设计思路是，可以使用 HashMap 存储 key，这样可以做到 save 和 get key的时间都是 O(1)，而 HashMap 的 Value 指向双向链表实现的 LRU 的 Node 节点，如图所示。LRU 存储是基于双向链表实现的，下面的图演示了它的原理。其中 head 代表双向链表的表头，tail 代表尾部。首先预先设置 LRU 的容量，如果存储满了，可以通过 O(1) 的时间淘汰掉双向链表的尾部，每次新增和访问数据，都可以通过 O(1)的效率把新的节点增加到对头，或者把已经存在的节点移动到队头。 「为什么用双向链表而不用单链表呢？」单链表能实现新来的放头部，最久不用的在尾部删除。但删除的时候需要遍历到尾部，因为单链表只有头指针。在用到已经用到过的数据时，还要遍历整合链表，来确定是否用过，然后再遍历到响应位置来剔除的节点，并重新放在头部。这效率可想而知。 这时hashmap的作用就出来了 他可以在单位[1]的时间判断value的值是否存在，key直接存储节点对象，能直接定位删除对应的节点(将比节点的父节点指向此节点的子节点)。 要通过一个节点直接获得父节点的话，通过单链表是不行的。这时双向链表的作用也提现出来了。能直接定位到父节点。 这效率就很高了。而且由于双向链表有尾指针，所以剔除最后的尾节点也十分方便，快捷。 4. 时钟置换算法（Clock）九、死锁8.1 死锁的四个条件👨‍💻面试官 ：产生死锁的四个必要条件是什么?🙋 我 ：如果系统中以下四个条件同时成立，那么就能引起死锁： 互斥：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。 占有并等待：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。 非抢占：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。 循环等待：有一组等待进程 {P0, P1,…, Pn}， P0 等待的资源被 P1 占有，P1 等待的资源被 P2 占有，……，Pn-1 等待的资源被 Pn 占有，Pn 等待的资源被 P0 占有。 注意，只有四个条件同时成立时，死锁才会出现。 8.2 解决死锁的方法解决死锁的方法可以从多个角度去分析，一般的情况下，有预防，避免，检测和解除四种。 预防 是采用某种策略，限制并发进程对资源的请求，从而使得死锁的必要条件在系统执行的任何时间上都不满足。 避免则是系统在分配资源时，根据资源的使用情况提前做出预测，从而避免死锁的发生 检测是指系统设有专门的机构，当死锁发生时，该机构能够检测死锁的发生，并精确地确定与死锁有关的进程和资源。 解除 是与检测相配套的一种措施，用于将进程从死锁状态下解脱出来。 a. 死锁的预防死锁四大必要条件上面都已经列出来了，很显然，只要破坏四个必要条件中的任何一个就能够预防死锁的发生。 破坏第一个条件 互斥条件：使得资源是可以同时访问的，但是我们要知道，有很多资源 往往是不能同时访问的 （也就是并发安全的），所以这种做法在大多数的场合是行不通的。 破坏第三个条件 非抢占 ：也就是说可以采用 剥夺式调度算法，但剥夺式调度方法目前一般仅适用于 主存资源 和 处理器资源 的分配，并不适用于所以的资源，会导致 资源利用率下降。 所以一般比较实用的 预防死锁的方法，是通过考虑破坏第二个条件(占有并等待)和第四个条件循环等待。1、静态分配策略 – 一次性请求所有资源静态分配策略可以破坏死锁产生的第二个条件（占有并等待）。所谓静态分配策略，就是指一个进程必须在执行前就申请到它所需要的全部资源，并且知道它所要的资源都得到满足之后才开始执行。进程要么占有所有的资源然后开始执行，要么不占有资源，不会出现占有一些资源等待一些资源的情况。静态分配策略逻辑简单，实现也很容易，但这种策略 严重地降低了资源利用率，因为在每个进程所占有的资源中，有些资源是在比较靠后的执行时间里采用的，甚至有些资源是在额外的情况下才是用的，这样就可能造成了一个进程占有了一些 几乎不用的资源而使其他需要该资源的进程产生等待 的情况。2、层次分配策略 – 按序申请资源层次分配策略破坏了产生死锁的第四个条件(循环等待)。在层次分配策略下，所有的资源被分成了多个层次，一个进程得到某一次的一个资源后，它只能再申请较高一层的资源；当一个进程要释放某层的一个资源时，必须先释放所占用的较高层的资源，按这种策略，是不可能出现循环等待链的，因为那样的话，就出现了已经申请了较高层的资源，反而去申请了较低层的资源，不符合层次分配策略，证明略。 b. 死锁的避免上面提到的 破坏 死锁产生的四个必要条件之一就可以成功 预防系统发生死锁 ，但是会导致 低效的进程运行 和 资源使用率 。而死锁的避免相反，它的角度是允许系统中同时存在四个必要条件 ，只要掌握并发进程中与每个进程有关的资源动态申请情况，做出 明智和合理的选择 ，仍然可以避免死锁，因为四大条件仅仅是产生死锁的必要条件。我们将系统的状态分为 安全状态 和 不安全状态 ，每当在未申请者分配资源前先测试系统状态，若把系统资源分配给申请者会产生死锁，则拒绝分配，否则接受申请，并为它分配资源。如果操作系统能够保证所有的进程在有限的时间内得到需要的全部资源，则称系统处于安全状态，否则说系统是不安全的。很显然，系统处于安全状态则不会发生死锁，系统若处于不安全状态则可能发生死锁。那么如何保证系统保持在安全状态呢？通过算法，其中最具有代表性的 避免死锁算法 就是 Dijkstra 的银行家算法，**「银行家算法」**用一句话表达就是：当一个进程申请使用资源的时候，银行家算法 通过先 试探 分配给该进程资源，然后通过 安全性算法 判断分配后系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待，若能够进入到安全的状态，则就 真的分配资源给该进程。银行家算法详情可见：《一句话+一张图说清楚——银行家算法》open in new window 。操作系统教程树中讲述的银行家算法也比较清晰，可以一看.死锁的避免(银行家算法)改善解决了 资源使用率低的问题 ，但是它要不断地检测每个进程对各类资源的占用和申请情况，以及做 安全性检查 ，需要花费较多的时间。 c. 死锁的检测对资源的分配加以限制可以 预防和避免 死锁的发生，但是都不利于各进程对系统资源的充分共享。解决死锁问题的另一条途径是 死锁检测和解除 (这里突然联想到了乐观锁和悲观锁，感觉死锁的检测和解除就像是 乐观锁 ，分配资源时不去提前管会不会发生死锁了，等到真的死锁出现了再来解决嘛，而 死锁的预防和避免 更像是悲观锁，总是觉得死锁会出现，所以在分配资源的时候就很谨慎)。这种方法对资源的分配不加以任何限制，也不采取死锁避免措施，但系统 定时地运行一个 “死锁检测” 的程序，判断系统内是否出现死锁，如果检测到系统发生了死锁，再采取措施去解除它。 进程-资源分配图操作系统中的每一刻时刻的系统状态都可以用进程-资源分配图来表示，进程-资源分配图是描述进程和资源申请及分配关系的一种有向图，可用于检测系统是否处于死锁状态。用一个方框表示每一个资源类，方框中的黑点表示该资源类中的各个资源，每个键进程用一个圆圈表示，用 有向边 来表示进程申请资源和资源被分配的情况。图中 2-21 是进程-资源分配图的一个例子，其中共有三个资源类，每个进程的资源占有和申请情况已清楚地表示在图中。在这个例子中，由于存在 占有和等待资源的环路 ，导致一组进程永远处于等待资源的状态，发生了 死锁。进程-资源分配图中存在环路并不一定是发生了死锁。因为循环等待资源仅仅是死锁发生的必要条件，而不是充分条件。图 2-22 便是一个有环路而无死锁的例子。虽然进程 P1 和进程 P3 分别占用了一个资源 R1 和一个资源 R2，并且因为等待另一个资源 R2 和另一个资源 R1 形成了环路，但进程 P2 和进程 P4 分别占有了一个资源 R1 和一个资源 R2，它们申请的资源得到了满足，在有限的时间里会归还资源，于是进程 P1 或 P3 都能获得另一个所需的资源，环路自动解除，系统也就不存在死锁状态了。 死锁检测步骤知道了死锁检测的原理，我们可以利用下列步骤编写一个 死锁检测 程序，检测系统是否产生了死锁。 如果进程-资源分配图中无环路，则此时系统没有发生死锁 如果进程-资源分配图中有环路，且每个资源类仅有一个资源，则系统中已经发生了死锁。 如果进程-资源分配图中有环路，且涉及到的资源类有多个资源，此时系统未必会发生死锁。如果能在进程-资源分配图中找出一个 既不阻塞又非独立的进程 ，该进程能够在有限的时间内归还占有的资源，也就是把边给消除掉了，重复此过程，直到能在有限的时间内 消除所有的边 ，则不会发生死锁，否则会发生死锁。(消除边的过程类似于 拓扑排序) d. 死锁的解除当死锁检测程序检测到存在死锁发生时，应设法让其解除，让系统从死锁状态中恢复过来，常用的解除死锁的方法有以下四种： 立即结束所有进程的执行，重新启动操作系统 ：这种方法简单，但以前所在的工作全部作废，损失很大。 撤销涉及死锁的所有进程，解除死锁后继续运行 ：这种方法能彻底打破死锁的循环等待条件，但将付出很大代价，例如有些进程可能已经计算了很长时间，由于被撤销而使产生的部分结果也被消除了，再重新执行时还要再次进行计算。 逐个撤销涉及死锁的进程，回收其资源直至死锁解除。 抢占资源 ：从涉及死锁的一个或几个进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除。 十、用户态与内核态Kernel 运行在超级权限模式下，所以拥有很高的权限。按照权限管理的原则，多数应用程序应该运行在最小权限下。因此，很多操作系统，将内存分成了两个区域： 内核空间（Kernal Space），这个空间只有内核程序可以访问； 用户空间（User Space），这部分内存专门给应用程序使用。 用户空间中的代码被限制了只能使用一个局部的内存空间，我们说这些程序在 用户态 执行。内核空间中的代码可以访问所有内存，我们称这些程序在 内核态 执行。 按照级别划分： 当程序运行在0级特权级上时，就可以称之为运行在内核态 当程序运行在3级特权级上时，就可以称之为运行在用户态 运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。 当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态（比如操作硬件） 这两种状态的主要差别 处于用户态执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理器是可被抢占的 处于内核态执行时，则能访问所有的内存空间和对象，且所占有的处理器是不允许被抢占的。为什么要有用户态和内核态 由于需要限制不同的程序之间的访问能力，防止他们获取别的程序的内存数据，或者获取外围设备的数据，并发送到网络用户态与内核态的切换 所有用户程序都是运行在用户态的，但是有时候程序确实需要做一些内核态的事情， 例如从硬盘读取数据，或者从键盘获取输入等，而唯一可以做这些事情的就是操作系统，所以此时程序就需要先操作系统请求以程序的名义来执行这些操作","categories":[],"tags":[{"name":"Operating System","slug":"Operating-System","permalink":"http://plus-l.github.io/tags/Operating-System/"}]},{"title":"","slug":"hello-world","date":"2022-10-09T01:35:40.221Z","updated":"2022-10-09T04:54:52.827Z","comments":true,"path":"2022/10/09/hello-world/","link":"","permalink":"http://plus-l.github.io/2022/10/09/hello-world/","excerpt":"","text":"Hello WorldWelcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"DataStructure and Algorithm,Princeton Algorithm","slug":"DataStructure-and-Algorithm-Princeton-Algorithm","permalink":"http://plus-l.github.io/tags/DataStructure-and-Algorithm-Princeton-Algorithm/"},{"name":"Operating System","slug":"Operating-System","permalink":"http://plus-l.github.io/tags/Operating-System/"}]}